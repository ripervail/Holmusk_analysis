{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis for Holmusk data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Downloads\\Holmusk_analysis\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our datasets\n",
    "bill_id = pd.read_csv(r'C:/Users/USER/Downloads/Holmusk_analysis/bill_id.csv')\n",
    "demographics = pd.read_csv(r'C:/Users/USER/Downloads/Holmusk_analysis/demographics.csv')\n",
    "clinical_data = pd.read_csv(r'C:/Users/USER/Downloads/Holmusk_analysis/clinical_data.csv')\n",
    "\n",
    "# Rename bill_id \"patient_id\" to avoid conflict\n",
    "bill_id.rename(columns={\"patient_id\": \"pt_id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bill_id columns: Index(['pt_id', 'bill_id', 'date_of_admission', 'amount'], dtype='object')\n",
      "demographics columns: Index(['patient_id', 'gender', 'race', 'resident_status', 'date_of_birth'], dtype='object')\n",
      "clinical_data columns: Index(['id', 'date_of_admission', 'date_of_discharge', 'medical_history_1',\n",
      "       'medical_history_2', 'medical_history_3', 'medical_history_4',\n",
      "       'medical_history_5', 'medical_history_6', 'medical_history_7',\n",
      "       'preop_medication_1', 'preop_medication_2', 'preop_medication_3',\n",
      "       'preop_medication_4', 'preop_medication_5', 'preop_medication_6',\n",
      "       'symptom_1', 'symptom_2', 'symptom_3', 'symptom_4', 'symptom_5',\n",
      "       'lab_result_1', 'lab_result_2', 'lab_result_3', 'weight', 'height'],\n",
      "      dtype='object')\n",
      " \n",
      "bill_id length: 13600\n",
      "demographics length: 3000\n",
      "clinical_data length: 3400\n"
     ]
    }
   ],
   "source": [
    "print(\"bill_id columns: \" + str(bill_id.columns))\n",
    "print(\"demographics columns: \" + str(demographics.columns))\n",
    "print(\"clinical_data columns: \" + str(clinical_data.columns))\n",
    "print(\" \")\n",
    "print(\"bill_id length: \" + str(len(bill_id)))\n",
    "print(\"demographics length: \" + str(len(demographics)))\n",
    "print(\"clinical_data length: \" + str(len(clinical_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bill_id actually has repeated patient ids, but with separate bill ids! Maybe we can just combine all the bill amounts together\n",
    "\n",
    "Seems like bill_id has 4 rows for each patient visit. Patients that visit more than once however, will have 4 * n rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bill_id: 3000 / 13600\n",
      "demographics: 3000 / 3000\n",
      "clinical_data: 3000 / 3400\n"
     ]
    }
   ],
   "source": [
    "# Find any repeated values\n",
    "print(\"bill_id: \" + str(len(bill_id[\"pt_id\"].unique())) + \" / \" + str(len(bill_id)))\n",
    "print(\"demographics: \" + str(len(demographics[\"patient_id\"].unique())) + \\\n",
    "      \" / \" + str(len(demographics)))\n",
    "print(\"clinical_data: \" + str(len(clinical_data[\"id\"].unique())) + \\\n",
    "      \" / \" + str(len(clinical_data)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's combine the bill_ids into the correct format.\n",
    "\n",
    "We add date_of_admission to their bill_ids to separate multiple visits by the same patient. Of course, we can look at the impact of multiple visits on the bill amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3400"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bill_id_2 = bill_id.copy(deep=True)\n",
    "\n",
    "# Save new id as id_w_date so we can reuse id to add in demographic info\n",
    "bill_id_2[\"id_w_date\"] = bill_id[\"pt_id\"] + bill_id[\"date_of_admission\"]\n",
    "\n",
    "# bill_id_2[\"pt_id\"][0]\n",
    "len(bill_id_2[\"id_w_date\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3400\n",
      "3400\n"
     ]
    }
   ],
   "source": [
    "bill_id_2 = bill_id_2.sort_values(\"id_w_date\")\n",
    "\n",
    "# Maybe we can check the vist number too!\n",
    "admission_count = []\n",
    "\n",
    "# Combine the bill amounts\n",
    "bill = []\n",
    "current = bill_id_2[\"id_w_date\"][0]\n",
    "total_bill = 0\n",
    "count = 1\n",
    "for index, row in bill_id_2.iterrows():\n",
    "    if row[\"id_w_date\"] == current:\n",
    "        total_bill += row[\"amount\"]\n",
    "        count += 1\n",
    "    else:\n",
    "        bill.append(total_bill)\n",
    "        admission_count.append((count // 4) + 1)\n",
    "        count = 0\n",
    "        current = row[\"id_w_date\"]\n",
    "        total_bill = row[\"amount\"]\n",
    "bill.append(total_bill)\n",
    "admission_count.append(count)\n",
    "\n",
    "print(len(bill))\n",
    "print(len(admission_count))\n",
    "\n",
    "# Bill has been combined!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12 // 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same for clinical_data, and sort it, and add in the bill.\n",
    "\n",
    "For clinical_data, we actually see that some patients have multiple logs, because they enter the hospital multiple times! We must treat those as separate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clinical_data processing\n",
    "cd_2 = clinical_data.copy(deep=True)\n",
    "cd_2[\"id_w_date\"] = clinical_data[\"id\"] + clinical_data[\"date_of_admission\"]\n",
    "\n",
    "# Sort by new patient id\n",
    "cd_2 = cd_2.sort_values(\"id_w_date\")\n",
    "\n",
    "# Add in total_bill\n",
    "cd_2[\"total_bill\"] = bill\n",
    "cd_2[\"admission_count\"] = admission_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add in the relevant demographic data into cd_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patient_id', 'gender', 'race', 'resident_status', 'date_of_birth'], dtype='object')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3400\n"
     ]
    }
   ],
   "source": [
    "# Add empty columns to cd_2\n",
    "gender = []\n",
    "race = []\n",
    "citizenship = []\n",
    "dob = []\n",
    "\n",
    "# Check patient id in demographic, and add to cd_2\n",
    "count_cd2 = 0\n",
    "count_demo = 0\n",
    "loop = 0\n",
    "while count_cd2 < 3400 and count_demo < 3000:\n",
    "#     print(loop)\n",
    "#     loop += 1\n",
    "    if cd_2[\"id\"][count_cd2] == demographics[\"patient_id\"][count_demo]:\n",
    "        gender.append(demographics[\"gender\"][count_demo])\n",
    "        race.append(demographics[\"race\"][count_demo])\n",
    "        citizenship.append(demographics[\"resident_status\"][count_demo])\n",
    "        dob.append(demographics[\"date_of_birth\"][count_demo])\n",
    "        count_cd2 += 1\n",
    "    else: \n",
    "        count_demo += 1\n",
    "        \n",
    "print(len(gender))\n",
    "\n",
    "# Add the columns\n",
    "cd_2[\"gender\"] = gender\n",
    "cd_2[\"race\"] = race\n",
    "cd_2[\"citizenship\"] = citizenship\n",
    "cd_2[\"date_of_birth\"] = dob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Female\n",
      "1       Female\n",
      "2         Male\n",
      "3       Female\n",
      "4         Male\n",
      "         ...  \n",
      "3395    Female\n",
      "3396      Male\n",
      "3397      Male\n",
      "3398      Male\n",
      "3399    Female\n",
      "Name: gender, Length: 3400, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(cd_2[\"gender\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compile into our full dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = cd_2.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'date_of_admission', 'date_of_discharge', 'medical_history_1',\n",
      "       'medical_history_2', 'medical_history_3', 'medical_history_4',\n",
      "       'medical_history_5', 'medical_history_6', 'medical_history_7',\n",
      "       'preop_medication_1', 'preop_medication_2', 'preop_medication_3',\n",
      "       'preop_medication_4', 'preop_medication_5', 'preop_medication_6',\n",
      "       'symptom_1', 'symptom_2', 'symptom_3', 'symptom_4', 'symptom_5',\n",
      "       'lab_result_1', 'lab_result_2', 'lab_result_3', 'weight', 'height',\n",
      "       'id_w_date', 'total_bill', 'admission_count', 'gender', 'race',\n",
      "       'citizenship', 'date_of_birth'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(raw_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the column values uniform and consistent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's clean up the data and make it code-readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medical_history_2 nulls: True\n",
      "medical_history_5 nulls: True\n",
      "233\n",
      "304\n"
     ]
    }
   ],
   "source": [
    "# Check NA\n",
    "for column in raw_df.columns:\n",
    "    if raw_df[column].isnull().values.any():\n",
    "        print(column + \" nulls: \" + str(raw_df[column].isnull().values.any()))\n",
    "        \n",
    "# Medical_history 2 and 5 have nulls. Let's check the number\n",
    "print(raw_df[\"medical_history_2\"].isnull().sum())\n",
    "print(raw_df[\"medical_history_5\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant number of nulls. While I think the dataset is big enough where we can just remove them, I want to see if there is any reason behind these nulls. \n",
    "\n",
    "So let's filter them out, and analyse them separately (later...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1702\n"
     ]
    }
   ],
   "source": [
    "# Rectify gender - no nulls\n",
    "# Male = 1, female = 0\n",
    "gender_df = raw_df.copy(deep=True)\n",
    "# print(gender_df[\"gender\"].isnull().sum())\n",
    "\n",
    "gender_df[\"gender\"] = np.where(gender_df[\"gender\"].str.lower().str.startswith(\"m\"), 1, 0)\n",
    "\n",
    "print(len(gender_df.loc[gender_df[\"gender\"] == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update gender\n",
    "raw_df[\"gender\"] = gender_df[\"gender\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative ages: 0\n",
      "3400\n"
     ]
    }
   ],
   "source": [
    "# Add in age column\n",
    "age_df = raw_df.copy(deep=True)\n",
    "# print(age_df[\"date_of_birth\"].isnull().sum()) # No nulls for both\n",
    "# print(age_df[\"date_of_admission\"].isnull().sum())\n",
    "\n",
    "doa = age_df[\"date_of_admission\"].str.split('/', expand=True).astype(int)\n",
    "dob = age_df[\"date_of_birth\"].str.split('/', expand=True).astype(int)\n",
    "\n",
    "age_at_admission = [a - b for a, b in zip(doa[2], dob[2])]\n",
    "\n",
    "# Check that there are no negative ages\n",
    "count = 0\n",
    "for age in age_at_admission:\n",
    "    if age < 0:\n",
    "        count += 1\n",
    "print(\"Negative ages: \" + str(count))\n",
    "print(len(age_at_admission))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df[\"age_at_admission\"] = age_at_admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's change date_of_admission and date_of_birth into month and year values\n",
    "yoa, moa = doa[2], doa[1]\n",
    "yob, mob = dob[2], dob[1]\n",
    "\n",
    "raw_df[\"year_of_admission\"] = yoa\n",
    "raw_df[\"month_of_admission\"] = moa\n",
    "raw_df[\"year_of_birth\"] = yob\n",
    "raw_df[\"month_of_birth\"] = mob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1983\n",
       "1       1943\n",
       "2       1972\n",
       "3       1976\n",
       "4       1942\n",
       "        ... \n",
       "3395    1976\n",
       "3396    1963\n",
       "3397    1938\n",
       "3398    1950\n",
       "3399    1956\n",
       "Name: year_of_birth, Length: 3400, dtype: int32"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all newly-formatted columns\n",
    "raw_df[\"year_of_birth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative durations: 0\n",
      "3400\n"
     ]
    }
   ],
   "source": [
    "# Change date_of_discharge to duration_of_stay\n",
    "# We make use of datetime object to do this for us\n",
    "# Date format is  DD/MM/YYYY\n",
    "from datetime import date\n",
    "\n",
    "duration_of_stay = []\n",
    "\n",
    "for index, row in raw_df.iterrows():\n",
    "    _doa = row[\"date_of_admission\"].split('/')\n",
    "    _dod = row[\"date_of_discharge\"].split('/')\n",
    "    d_a = date(int(_doa[2]), int(_doa[1]), int(_doa[0]))\n",
    "    d_d = date(int(_dod[2]), int(_dod[1]), int(_dod[0]))\n",
    "    duration_of_stay.append((d_d - d_a).days)\n",
    "    \n",
    "# Check negative duration\n",
    "count = 0\n",
    "for day in duration_of_stay:\n",
    "    if day < 0:\n",
    "        count += 1\n",
    "        \n",
    "print(\"Negative durations: \" + str(count))\n",
    "print(len(duration_of_stay))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, handle missing values for medical condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lastly, let's clean up the data and remove unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['pt_id' 'id'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-1865141030e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Remove duplicate patient id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mraw_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pt_id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4165\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4166\u001b[0m         \"\"\"\n\u001b[1;32m-> 4167\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4168\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4169\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3887\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3888\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3889\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3891\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3921\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3922\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3923\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3924\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3925\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5285\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5286\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5287\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5288\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5289\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['pt_id' 'id'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Remove duplicate unneeded columns at the end\n",
    "raw_df = raw_df.drop(columns=[\"pt_id\", \"id\"])\n",
    "print(raw_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets export this full dataset, and then shift the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_df.to_csv(\"raw_df.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
